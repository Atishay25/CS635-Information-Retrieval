{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\n\n# Define transforms for data augmentation and normalization\ntransform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\n# Load CIFAR-10 dataset\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n\n# Create DataLoader for batch processing\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=1000, shuffle=False, num_workers=2)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=1000, shuffle=False, num_workers=2)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-09T14:33:16.540648Z","iopub.execute_input":"2024-10-09T14:33:16.541505Z","iopub.status.idle":"2024-10-09T14:33:23.884577Z","shell.execute_reply.started":"2024-10-09T14:33:16.541467Z","shell.execute_reply":"2024-10-09T14:33:23.883771Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170498071/170498071 [00:03<00:00, 44877109.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/cifar-10-python.tar.gz to ./data\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch.nn as nn\nimport torchvision.models as models\nimport numpy as np\n\n# Load pretrained ResNet model and modify it to act as a feature extractor\nresnet18 = models.resnet18(pretrained=True)\nresnet18 = nn.Sequential(*list(resnet18.children())[:-1])  # Remove the final classification layer\n\n# Function to extract features\ndef extract_features(dataloader):\n    resnet18.eval()  # Set model to evaluation mode\n    features = []\n    labels = []\n    with torch.no_grad():\n        for inputs, targets in dataloader:\n            outputs = resnet18(inputs).squeeze()\n            features.append(outputs.cpu().numpy())\n            labels.append(targets.numpy())\n    return np.vstack(features), np.hstack(labels)\n\n# Extract features from train and test set\ntrain_features, train_labels = extract_features(trainloader)\ntest_features, test_labels = extract_features(testloader)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-09T14:34:29.787487Z","iopub.execute_input":"2024-10-09T14:34:29.787877Z","iopub.status.idle":"2024-10-09T14:35:14.076564Z","shell.execute_reply.started":"2024-10-09T14:34:29.787839Z","shell.execute_reply":"2024-10-09T14:35:14.075137Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from sklearn.cluster import KMeans\nimport numpy as np\n\n# Apply K-means clustering to training set\nkmeans = KMeans(n_clusters=10, random_state=42)\n\ntrain_clusters = kmeans.fit_predict(train_features)","metadata":{"execution":{"iopub.status.busy":"2024-10-09T14:35:34.425427Z","iopub.execute_input":"2024-10-09T14:35:34.426324Z","iopub.status.idle":"2024-10-09T14:36:09.898300Z","shell.execute_reply.started":"2024-10-09T14:35:34.426283Z","shell.execute_reply":"2024-10-09T14:36:09.897252Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# Assign each test image to its nearest cluster\ntest_clusters = kmeans.predict(test_features)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-09T14:36:09.900222Z","iopub.execute_input":"2024-10-09T14:36:09.900971Z","iopub.status.idle":"2024-10-09T14:36:09.911467Z","shell.execute_reply.started":"2024-10-09T14:36:09.900923Z","shell.execute_reply":"2024-10-09T14:36:09.910515Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_similarity\n\ndef get_top_k_matches(test_feature, cluster_indices, k=50):\n    # Get the features of images belonging to the same cluster\n    cluster_features = train_features[cluster_indices]\n    \n    # Compute cosine similarity between the test image and cluster images\n    similarities = cosine_similarity(test_feature.reshape(1, -1), cluster_features).flatten()\n    \n    # Get the top k most similar images\n    top_k_indices = np.argsort(similarities)[::-1][:k]\n    return cluster_indices[top_k_indices]\n\n# For each test image, find the top 50 matches\ntop_k_matches = []\nfor i, test_feature in enumerate(test_features):\n    # Find the training images belonging to the same cluster\n    cluster_indices = np.where(train_clusters == test_clusters[i])[0]\n    \n    # Get the top 50 matches based on cosine similarity\n    top_k_matches.append(get_top_k_matches(test_feature, cluster_indices))\n","metadata":{"execution":{"iopub.status.busy":"2024-10-09T14:36:10.016746Z","iopub.execute_input":"2024-10-09T14:36:10.017386Z","iopub.status.idle":"2024-10-09T14:38:53.818442Z","shell.execute_reply.started":"2024-10-09T14:36:10.017347Z","shell.execute_reply":"2024-10-09T14:38:53.816740Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def precision_at_k(true_label, top_k_labels, k):\n    top_k = top_k_labels[:k]\n    correct = np.sum(top_k == true_label)\n    return correct / k\n\ndef mean_average_precision(true_label, top_k_labels):\n    # Calculate precision at each rank and then compute average precision\n    precisions = []\n    correct = 0\n    for i, label in enumerate(top_k_labels):\n        if label == true_label:\n            correct += 1\n            precisions.append(correct / (i + 1))\n    return np.mean(precisions) if precisions else 0\n\n# Evaluate for all test images\nprecision_10 = []\nprecision_50 = []\nmean_ap = []\nfor i, matches in enumerate(top_k_matches):\n    true_label = test_labels[i]\n    matched_labels = train_labels[matches]\n    \n    precision_10.append(precision_at_k(true_label, matched_labels, 10))\n    precision_50.append(precision_at_k(true_label, matched_labels, 50))\n    mean_ap.append(mean_average_precision(true_label, matched_labels))\n\n# Report final metrics\nprint(f'Mean Precision@10: {np.mean(precision_10):.4f}')\nprint(f'Mean Precision@50: {np.mean(precision_50):.4f}')\nprint(f'Mean Average Precision: {np.mean(mean_ap):.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-10-09T14:38:53.820535Z","iopub.execute_input":"2024-10-09T14:38:53.824744Z","iopub.status.idle":"2024-10-09T14:38:54.426070Z","shell.execute_reply.started":"2024-10-09T14:38:53.824687Z","shell.execute_reply":"2024-10-09T14:38:54.425135Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Mean Precision@10: 0.4224\nMean Precision@50: 0.3724\nMean Average Precision: 0.4547\n","output_type":"stream"}]}]}