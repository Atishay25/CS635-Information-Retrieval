{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\n\n# Define transforms for data augmentation and normalization\ntransform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\n# Load CIFAR-10 dataset\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n\n# Create DataLoader for batch processing\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=1000, shuffle=False, num_workers=2)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=1000, shuffle=False, num_workers=2)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-09T15:26:36.485383Z","iopub.execute_input":"2024-10-09T15:26:36.485720Z","iopub.status.idle":"2024-10-09T15:26:50.689944Z","shell.execute_reply.started":"2024-10-09T15:26:36.485675Z","shell.execute_reply":"2024-10-09T15:26:50.688883Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170498071/170498071 [00:04<00:00, 34199506.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/cifar-10-python.tar.gz to ./data\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch.nn as nn\nimport torchvision.models as models\nimport numpy as np\nfrom tqdm import tqdm\n\n# Load pretrained ResNet model and modify it to act as a feature extractor\nresnet18 = models.resnet18(pretrained=True)\nresnet18 = nn.Sequential(*list(resnet18.children())[:-1])  # Remove the final classification layer\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nresnet18 = resnet18.to(device)\n\n# Function to extract features\ndef extract_features(dataloader, dataset_name='Dataset'):\n    resnet18.eval()  # Set model to evaluation mode\n    features = []\n    labels = []\n    with torch.no_grad():\n        for inputs, targets in tqdm(dataloader, desc=f'Extracting features from {dataset_name}', unit='batch', total=len(dataloader)):\n            outputs = resnet18(inputs.to(device)).squeeze()\n            features.append(outputs.cpu().numpy())\n            labels.append(targets.numpy())\n    return np.vstack(features), np.hstack(labels)\n\n\n\n# Extract features from train and test set\ntrain_features, train_labels = extract_features(trainloader, 'Train Set')\ntest_features, test_labels = extract_features(testloader, 'Test Set')","metadata":{"execution":{"iopub.status.busy":"2024-10-09T15:26:50.692042Z","iopub.execute_input":"2024-10-09T15:26:50.692477Z","iopub.status.idle":"2024-10-09T15:27:02.619891Z","shell.execute_reply.started":"2024-10-09T15:26:50.692441Z","shell.execute_reply":"2024-10-09T15:27:02.618647Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 103MB/s] \nExtracting features from Train Set: 100%|██████████| 50/50 [00:08<00:00,  5.59batch/s]\nExtracting features from Test Set: 100%|██████████| 10/10 [00:01<00:00,  5.91batch/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.cluster import KMeans\nimport numpy as np\n\n# Apply K-means clustering to training set\nkmeans = KMeans(n_clusters=10, random_state=42)\n\ntrain_clusters = kmeans.fit_predict(train_features)\n\n# Assign each test image to its nearest cluster\ntest_clusters = kmeans.predict(test_features)","metadata":{"execution":{"iopub.status.busy":"2024-10-09T15:27:02.621421Z","iopub.execute_input":"2024-10-09T15:27:02.621789Z","iopub.status.idle":"2024-10-09T15:27:42.371663Z","shell.execute_reply.started":"2024-10-09T15:27:02.621749Z","shell.execute_reply":"2024-10-09T15:27:42.370559Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_similarity\n\ndef get_top_k_matches(test_feature, cluster_indices, k=50):\n    # Get the features of images belonging to the same cluster\n    cluster_features = train_features[cluster_indices]\n    \n    # Compute cosine similarity between the test image and cluster images\n    similarities = cosine_similarity(test_feature.reshape(1, -1), cluster_features).flatten()\n    \n    # Get the top k most similar images\n    top_k_indices = np.argsort(similarities)[::-1][:k]\n    return cluster_indices[top_k_indices]\n\n\n# For each test image, find the top 50 matches\ntop_k_matches = []\nfor i, test_feature in tqdm(enumerate(test_features), desc='Finding Top-K Matches', unit='image', total=len(test_features)):\n    # Find the training images belonging to the same cluster\n    cluster_indices = np.where(train_clusters == test_clusters[i])[0]\n    \n    # Get the top 50 matches based on cosine similarity\n    top_k_matches.append(get_top_k_matches(test_feature, cluster_indices))\n","metadata":{"execution":{"iopub.status.busy":"2024-10-09T15:27:42.373770Z","iopub.execute_input":"2024-10-09T15:27:42.374318Z","iopub.status.idle":"2024-10-09T15:30:49.460310Z","shell.execute_reply.started":"2024-10-09T15:27:42.374279Z","shell.execute_reply":"2024-10-09T15:30:49.458760Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"Finding Top-K Matches: 100%|██████████| 10000/10000 [03:07<00:00, 53.46image/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"def precision_at_k(true_label, top_k_labels, k):\n    top_k = top_k_labels[:k]\n    correct = np.sum(top_k == true_label)\n    return correct / k\n\ndef mean_average_precision(true_label, top_k_labels):\n    # Calculate precision at each rank and then compute average precision\n    precisions = []\n    correct = 0\n    for i, label in enumerate(top_k_labels):\n        if label == true_label:\n            correct += 1\n            precisions.append(correct / (i + 1))\n    return np.mean(precisions) if precisions else 0\n\n# Evaluate for all test images\nprecision_10 = []\nprecision_50 = []\nmean_ap = []\nfor i, matches in tqdm(enumerate(top_k_matches), desc='Evaluating Metrics', unit='image', total=len(top_k_matches)):\n    true_label = test_labels[i]\n    matched_labels = train_labels[matches]\n    \n    precision_10.append(precision_at_k(true_label, matched_labels, 10))\n    precision_50.append(precision_at_k(true_label, matched_labels, 50))\n    mean_ap.append(mean_average_precision(true_label, matched_labels))\n\n# Report final metrics\nprint(f'Mean Precision@10: {np.mean(precision_10):.4f}')\nprint(f'Mean Precision@50: {np.mean(precision_50):.4f}')\nprint(f'Mean Average Precision: {np.mean(mean_ap):.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-10-09T15:30:49.467265Z","iopub.execute_input":"2024-10-09T15:30:49.471057Z","iopub.status.idle":"2024-10-09T15:30:50.154622Z","shell.execute_reply.started":"2024-10-09T15:30:49.470975Z","shell.execute_reply":"2024-10-09T15:30:50.153477Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"Evaluating Metrics: 100%|██████████| 10000/10000 [00:00<00:00, 15351.19image/s]","output_type":"stream"},{"name":"stdout","text":"Mean Precision@10: 0.4224\nMean Precision@50: 0.3724\nMean Average Precision: 0.4547\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]}]}